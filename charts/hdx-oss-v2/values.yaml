global:
  imageRegistry: ""
  # List of image pull secrets to use for pulling images from private registries
  # This helps avoid rate limiting (429 errors) when pulling from Docker Hub
  # Example:
  # imagePullSecrets:
  #   - name: regcred
  #   - name: docker-hub-secret
  imagePullSecrets: []
  storageClassName: "gp3"
  # Keep PVCs when uninstalling helm release to preserve data
  keepPVC: false

hyperdx:
  image:
    repository: docker.hyperdx.io/hyperdx/hyperdx
    tag: 
    pullPolicy: IfNotPresent
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    enabled: true
    initialDelaySeconds: 1
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  # Add nodeSelector and tolerations for hyperdx service
  nodeSelector: {}
    # Example:
    # kubernetes.io/os: linux
    # node-role.kubernetes.io/worker: "true"
  tolerations: []
    # Example:
    # - key: "key1"
    #   operator: "Equal"
    #   value: "value1"
    #   effect: "NoSchedule"
  apiKey: "10dd0541-4631-4b41-981d-2fdff1f68ee5"
  apiPort: 8000
  appPort: 3000
  opampPort: 4320
  # The URL that will be use to access the frontend. Defaults to the http://localhost:3000.
  # If you have an ingress enabled, you should set this to the ingress host with the protocol. E.g. https://hdx-my-domain.com
  frontendUrl: "https://dev-hyperdx.k8s.shoplive.cloud"
  # frontendUrl: "{{ .Values.hyperdx.appUrl }}:{{ .Values.hyperdx.appPort }}"
  logLevel: "info"
  usageStatsEnabled: false
  # Endpoint to send hyperdx logs/traces/metrics to.Defaults to the chart's otel collector endpoint.
  otelExporterEndpoint: http://{{ include "hdx-oss.fullname" . }}-otel-collector:{{ .Values.otel.httpPort }}
  mongoUri: mongodb://neo:trinity34%23%24@dev-shoplive-shortform-cluster.cluster-chugiecaksxb.ap-northeast-2.docdb.amazonaws.com:27017/hyperdx?retryWrites=false&authMechanism=SCRAM-SHA-1
  # mongoUri: mongodb://{{ include "hdx-oss.fullname" . }}-mongodb:{{ .Values.mongodb.port }}/hyperdx
  annotations: {}
    # myAnnotation: "myValue"

  # Pod-level labels (applied to the deployment pods)
  labels: {}
    # myLabel: "myValue"
  env:
    - name: NEXTAUTH_URL
      value: "https://dev-hyperdx.k8s.shoplive.cloud"
    - name: USAGE_STATS_ENABLED
      value: "false"
    # Additional environment variables can be configured here
    # This is preserved for backward compatibility and advanced use cases

  # Default connections and sources (ENABLED BY DEFAULT)
  # Set to empty string to disable: defaultConnections: "" or defaultSources: ""
  # 
  # To use an existing secret instead of inline configuration, set:
  # useExistingConfigSecret: true
  # existingConfigSecret: "my-hyperdx-config"
  # existingConfigConnectionsKey: "connections.json"  # defaults to "connections.json"
  # existingConfigSourcesKey: "sources.json"  # defaults to "sources.json"
  #
  # The secret should contain separate keys for connections and sources JSON arrays
  useExistingConfigSecret: false
  existingConfigSecret: ""
  existingConfigConnectionsKey: ""
  existingConfigSourcesKey: ""
  
  defaultConnections: |
    [
      {
        "name": "ClickHouse Cloud",
        "host": "https://fw9e14z6df.us-east-2.aws.clickhouse.cloud:8443",
        "port": 8443,
        "username": "backendDeveloper",
        "password": "Trinity345#$%"
      }
    ]

  # Set to empty string to disable: defaultSources: ""
  defaultSources: |
    [
      {
        "from": {
          "databaseName": "otel_dev",
          "tableName": "otel_logs"
        },
        "kind": "log",
        "timestampValueExpression": "TimestampTime",
        "name": "Logs",
        "displayedTimestampValueExpression": "Timestamp",
        "implicitColumnExpression": "Body",
        "serviceNameExpression": "ServiceName",
        "bodyExpression": "Body",
        "eventAttributesExpression": "LogAttributes",
        "resourceAttributesExpression": "ResourceAttributes",
        "defaultTableSelectExpression": "Timestamp,ServiceName,SeverityText,Body",
        "severityTextExpression": "SeverityText",
        "traceIdExpression": "TraceId",
        "spanIdExpression": "SpanId",
        "connection": "Local ClickHouse",
        "traceSourceId": "Traces",
        "sessionSourceId": "Sessions",
        "metricSourceId": "Metrics"
      },
      {
        "from": {
          "databaseName": "otel_dev",
          "tableName": "otel_traces"
        },
        "kind": "trace",
        "timestampValueExpression": "Timestamp",
        "name": "Traces",
        "displayedTimestampValueExpression": "Timestamp",
        "implicitColumnExpression": "SpanName",
        "serviceNameExpression": "ServiceName",
        "bodyExpression": "SpanName",
        "eventAttributesExpression": "SpanAttributes",
        "resourceAttributesExpression": "ResourceAttributes",
        "defaultTableSelectExpression": "Timestamp,ServiceName,StatusCode,round(Duration/1e6),SpanName",
        "traceIdExpression": "TraceId",
        "spanIdExpression": "SpanId",
        "durationExpression": "Duration",
        "durationPrecision": 9,
        "parentSpanIdExpression": "ParentSpanId",
        "spanNameExpression": "SpanName",
        "spanKindExpression": "SpanKind",
        "statusCodeExpression": "StatusCode",
        "statusMessageExpression": "StatusMessage",
        "connection": "Local ClickHouse",
        "logSourceId": "Logs",
        "sessionSourceId": "Sessions",
        "metricSourceId": "Metrics"
      },
      {
        "from": {
          "databaseName": "otel_dev",
          "tableName": ""
        },
        "kind": "metric",
        "timestampValueExpression": "TimeUnix",
        "name": "Metrics",
        "resourceAttributesExpression": "ResourceAttributes",
        "metricTables": {
          "gauge": "otel_metrics_gauge",
          "histogram": "otel_metrics_histogram",
          "sum": "otel_metrics_sum",
          "_id": "682586a8b1f81924e628e808",
          "id": "682586a8b1f81924e628e808"
        },
        "connection": "Local ClickHouse",
        "logSourceId": "Logs",
        "traceSourceId": "Traces",
        "sessionSourceId": "Sessions"
      },
      {
        "from": {
          "databaseName": "otel_dev",
          "tableName": "hyperdx_sessions"
        },
        "kind": "session",
        "timestampValueExpression": "TimestampTime",
        "name": "Sessions",
        "displayedTimestampValueExpression": "Timestamp",
        "implicitColumnExpression": "Body",
        "serviceNameExpression": "ServiceName",
        "bodyExpression": "Body",
        "eventAttributesExpression": "LogAttributes",
        "resourceAttributesExpression": "ResourceAttributes",
        "defaultTableSelectExpression": "Timestamp,ServiceName,SeverityText,Body",
        "severityTextExpression": "SeverityText",
        "traceIdExpression": "TraceId",
        "spanIdExpression": "SpanId",
        "connection": "Local ClickHouse",
        "logSourceId": "Logs",
        "traceSourceId": "Traces",
        "metricSourceId": "Metrics"
      }
    ]

  # See https://github.com/hyperdxio/hyperdx/blob/v2/packages/api/docs/auto_provision/AUTO_PROVISION.md
  # for detailed configuration options

  ingress:
    enabled: false
    ingressClassName: nginx
    annotations: {}
    # The host to use for the ingress. Defaults to localhost. Be sure to update hyperdx.frontendUrl with this host value + protocol
    host: "localhost"  # Production domain
    path: "/(.*)"
    pathType: "ImplementationSpecific"
    proxyBodySize: "100m"
    proxyConnectTimeout: "60"
    proxySendTimeout: "60"
    proxyReadTimeout: "60"
    tls:
      enabled: false
      secretName: "hyperdx-tls"

    # Additional ingresses - these will only be rendered if the whole ingress object is enabled
    # This should be used to expose other deployments/services from the helm chart on the cluster
    # e.g. expose the OTEL collector.
    additionalIngresses: []
    # - name: otel-collector
    #   annotations: {}
    #   ingressClassName: nginx
    #   hosts:
    #     - host: collector.example.com
    #       paths:
    #         - path: /
    #           pathType: Prefix
    #           port: 4318
    #   tls:
    #     - secretName: otel-collector-tls
    #       hosts:
    #         - collector.example.com

  replicas: 1

  podDisruptionBudget:
    enabled: false

  # Service configuration
  service:
    type: ClusterIP  # Use ClusterIP for security. For external access, use ingress with proper TLS and authentication
    # Service-level annotations (applied to the Kubernetes service resource)
    annotations: {}
      # Example service annotations:
      # service.beta.kubernetes.io/aws-load-balancer-internal: "true"
      # cloud.google.com/load-balancer-type: "Internal"

mongodb:
  enabled: false
  image: "mongo:5.0.14-focal"
  port: 27017
  # Add nodeSelector and tolerations for mongodb service
  nodeSelector: {}
    # Example:
    # kubernetes.io/os: linux
    # node-role.kubernetes.io/worker: "true"
  tolerations: []
    # Example:
    # - key: "key1"
    #   operator: "Equal"
    #   value: "value1"
    #   effect: "NoSchedule"
  persistence:
    enabled: false
    dataSize: 10Gi
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    enabled: true
    initialDelaySeconds: 1
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3

clickhouse:
  enabled: false
  image: "clickhouse/clickhouse-server:24-alpine"
  port: 8123
  nativePort: 9000
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    enabled: true
    initialDelaySeconds: 1
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  # Add nodeSelector and tolerations for clickhouse service
  nodeSelector: {}
    # Example:
    # kubernetes.io/os: linux
    # node-role.kubernetes.io/worker: "true"
  tolerations: []
    # Example:
    # - key: "key1"
    #   operator: "Equal"
    #   value: "value1"
    #   effect: "NoSchedule"

  # Service configuration
  service:
    type: ClusterIP  # Use ClusterIP for security. For external access, use ingress with proper TLS and authentication
    # Service-level annotations (applied to the Kubernetes service resource)
    annotations: {}
      # Example service annotations:
      # service.beta.kubernetes.io/aws-load-balancer-internal: "true"
      # cloud.google.com/load-balancer-type: "Internal"

  persistence:
    enabled: true
    dataSize: 10Gi
    logSize: 5Gi
  prometheus:
    enabled: true
    port: 9363
    endpoint: "/metrics"
  config:
    users:
      appUserPassword: "hyperdx"
      otelUserPassword: "otelcollectorpass"
      otelUserName: "otelcollector"
    # Network CIDRs for Kubernetes cluster access control
    # These CIDRs ensure ClickHouse connections are locked down to intra-cluster only
    # For PRODUCTION: Remove development CIDRs and keep only your cluster's specific CIDR
    # For DEVELOPMENT: Multiple common CIDRs are included for convenience
    clusterCidrs:
      - "10.0.0.0/8"        # Most Kubernetes clusters (including GKE, EKS, AKS)
      - "172.16.0.0/12"     # Some cloud providers and Docker Desktop
      - "192.168.0.0/16"    # OrbStack, Minikube, and local development

otel:
  enabled: true
  image:
    repository: docker.hyperdx.io/hyperdx/hyperdx-otel-collector
    tag:
    pullPolicy: IfNotPresent
  replicas: 1
  resources:
    requests:
      memory: "1024Mi"
      cpu: "1000m"
    limits:
      memory: "1.5Gi"
      cpu: "2000m"
  # Pod-level annotations (applied to the deployment pods)
  annotations: {}
    # myAnnotation: "myValue"
  # Add nodeSelector and tolerations for otel-collector service
  nodeSelector: {}
    # Example:
    # kubernetes.io/os: linux
    # node-role.kubernetes.io/worker: "true"
  tolerations: []
    # Example:
    # - key: "key1"
    #   operator: "Equal"
    #   value: "value1"
    #   effect: "NoSchedule"
  port: 13133
  nativePort: 24225
  grpcPort: 4317
  httpPort: 4318
  healthPort: 8888
  customConfig: |
    receivers:
      otlp/hyperdx:
        protocols:
          grpc:
            include_metadata: true
            endpoint: '0.0.0.0:4317'
          http:
            cors:
              allowed_origins: ['*']
              allowed_headers: ['*']
            include_metadata: true
            endpoint: '0.0.0.0:4318'
    processors:
      transform:
        log_statements:
          - context: log
            error_mode: ignore
            statements:
              # JSON parsing: Extends log attributes with the fields from structured log body content, either as an OTEL map or
              # as a string containing JSON content.
              - set(log.cache, ExtractPatterns(log.body, "(?P<0>(\\{.*\\}))")) where
                IsString(log.body)
              - merge_maps(log.attributes, ParseJSON(log.cache["0"]), "upsert")
                where IsMap(log.cache)
              - flatten(log.attributes) where IsMap(log.cache)
              - merge_maps(log.attributes, log.body, "upsert") where IsMap(log.body)
          - context: log
            error_mode: ignore
            conditions:
              - severity_number == 0 and severity_text == ""
            statements:
              # Infer: extract the first log level keyword from the first 256 characters of the body
              - set(log.cache["substr"], log.body.string) where Len(log.body.string)
                < 256
              - set(log.cache["substr"], Substring(log.body.string, 0, 256)) where
                Len(log.body.string) >= 256
              - set(log.cache, ExtractPatterns(log.cache["substr"],
                "(?i)(?P<0>(alert|crit|emerg|fatal|error|err|warn|notice|debug|dbug|trace))"))
              # Infer: detect FATAL
              - set(log.severity_number, SEVERITY_NUMBER_FATAL) where
                IsMatch(log.cache["0"], "(?i)(alert|crit|emerg|fatal)")
              - set(log.severity_text, "fatal") where log.severity_number ==
                SEVERITY_NUMBER_FATAL
              # Infer: detect ERROR
              - set(log.severity_number, SEVERITY_NUMBER_ERROR) where
                IsMatch(log.cache["0"], "(?i)(error|err)")
              - set(log.severity_text, "error") where log.severity_number ==
                SEVERITY_NUMBER_ERROR
              # Infer: detect WARN
              - set(log.severity_number, SEVERITY_NUMBER_WARN) where
                IsMatch(log.cache["0"], "(?i)(warn|notice)")
              - set(log.severity_text, "warn") where log.severity_number ==
                SEVERITY_NUMBER_WARN
              # Infer: detect DEBUG
              - set(log.severity_number, SEVERITY_NUMBER_DEBUG) where
                IsMatch(log.cache["0"], "(?i)(debug|dbug)")
              - set(log.severity_text, "debug") where log.severity_number ==
                SEVERITY_NUMBER_DEBUG
              # Infer: detect TRACE
              - set(log.severity_number, SEVERITY_NUMBER_TRACE) where
                IsMatch(log.cache["0"], "(?i)(trace)")
              - set(log.severity_text, "trace") where log.severity_number ==
                SEVERITY_NUMBER_TRACE
              # Infer: else
              - set(log.severity_text, "info") where log.severity_number == 0
              - set(log.severity_number, SEVERITY_NUMBER_INFO) where log.severity_number == 0
          - context: log
            error_mode: ignore
            statements:
              # Normalize the severity_text case
              - set(log.severity_text, ConvertCase(log.severity_text, "lower"))
      resourcedetection:
        detectors:
          - env
          - system
          - docker
        timeout: 5s
        override: false
      batch:
      memory_limiter:
        # 80% of maximum memory up to 2G, adjust for low memory environments
        limit_mib: 512
        # 25% of limit up to 2G, adjust for low memory environments
        spike_limit_mib: 256
        check_interval: 5s
    connectors:
      routing/logs:
        default_pipelines: [logs/out-default]
        error_mode: ignore
        table:
          - context: log
            statement: route() where IsMatch(attributes["rr-web.event"], ".*")
            pipelines: [logs/out-rrweb]
    exporters:
      debug:
        verbosity: detailed
        sampling_initial: 5
        sampling_thereafter: 200
      clickhouse/rrweb:
        database: ${env:HYPERDX_OTEL_EXPORTER_CLICKHOUSE_DATABASE}
        endpoint: ${env:CLICKHOUSE_ENDPOINT}
        password: ${env:CLICKHOUSE_PASSWORD}
        username: ${env:CLICKHOUSE_USER}
        create_schema: false
        ttl: 720h
        logs_table_name: hyperdx_sessions
        timeout: 5s
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s
      clickhouse:
        database: ${env:HYPERDX_OTEL_EXPORTER_CLICKHOUSE_DATABASE}
        endpoint: ${env:CLICKHOUSE_ENDPOINT}
        password: ${env:CLICKHOUSE_PASSWORD}
        username: ${env:CLICKHOUSE_USER}
        create_schema: false
        ttl: 720h
        timeout: 5s
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s
    extensions:
      health_check:
        endpoint: :13133
    service:
      pipelines:
        traces:
          receivers: [otlp/hyperdx]
          processors: [memory_limiter, batch]
          exporters: [clickhouse]
        metrics:
          receivers: [otlp/hyperdx]
          processors: [memory_limiter, batch]
          exporters: [clickhouse]
        logs/in:
          receivers: [otlp/hyperdx]
          exporters: [routing/logs]
        logs/out-default:
          receivers: [routing/logs]
          processors: [memory_limiter, transform, batch]
          exporters: [clickhouse]
        logs/out-rrweb:
          receivers: [routing/logs]
          processors: [memory_limiter, batch]
          exporters: [clickhouse/rrweb]

  env:
    - name: OTEL_LOG_LEVEL
      value: "info"
    # Additional environment variables can be configured here
    # Example:
    # - name: CUSTOM_VAR
    #   value: "my-value"
    # - name: SECRET_VAR
    #   valueFrom:
    #     secretKeyRef:
    #       name: my-secret
    #       key: secret-key
  # Opamp server URL - defaults to the app service. Customize if you want to use a different Opamp server.
  # Leave empty if you want to use the app service.
  # Example: opampServerUrl: "http://custom-opamp-server:4320"
  opampServerUrl:
  # Clickhouse endpoint - defaults to chart's Clickhouse service. Customize if you want to use a different Clickhouse service.
  # Leave empty if you want to use the chart's Clickhouse service.
  # Example: clickhouseEndpoint: "tcp://custom-clickhouse-service:9000"
  clickhouseEndpoint: https://fw9e14z6df.us-east-2.aws.clickhouse.cloud:8443
  clickhouseUser: "backendDeveloper"
  clickhousePassword: "Trinity345#$%"
  # Clickhouse Prometheus endpoint - defaults to chart's Clickhouse prometheus service. Customize if you want to use a different Clickhouse prometheus service.
  # Leave empty if prometheus is disabled.
  # Example: clickhousePrometheusEndpoint: "http://custom-clickhouse-service:9363"
  clickhousePrometheusEndpoint: ""
  # Clickhouse database to send logs/traces/metrics to. Defaults to "default"
  clickhouseDatabase: "otel_dev"
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    enabled: true
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3

tasks:
  enabled: false
  checkAlerts:
    schedule: "*/1 * * * *"  # Runs every 1 minute
    resources:
      limits:
        cpu: 200m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 256Mi

